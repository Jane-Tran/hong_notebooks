{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Quan sát dữ liệu</h2>\n",
    "\n",
    "Đầu tiên, ta sẽ import các thư viện cần thiết cho tutorial này"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sau đó, ta xây dựng các hàm helpers để tính thời gian tính toán và load tập dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_diff_str(t1, t2):\n",
    "    \"\"\"\n",
    "    Calculates time durations.\n",
    "    \"\"\"\n",
    "    diff = t2 - t1\n",
    "    mins = int(diff / 60)\n",
    "    secs = round(diff % 60, 2)\n",
    "    return str(mins) + \" mins and \" + str(secs) + \" seconds\"\n",
    "\n",
    "def load_wiki_data(file_name):\n",
    "    \"\"\"Get reviews data, from local csv.\"\"\"\n",
    "    if os.path.exists(file_name):\n",
    "        print(\"-- \" + file_name + \" found locally\")\n",
    "        df = pd.read_csv(file_name)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiếp theo, ta thử quan sát tập dữ liệu vừa download được bằng cách đọc tập dữ liệu này lên và đếm số dòng dữ liệu bên trong (chú ý, tập dữ liệu đã được chuyển đổi sang file csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- data/people_wiki.csv found locally\n",
      "(59071, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URI</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Digby_Morrell&gt;</td>\n",
       "      <td>Digby Morrell</td>\n",
       "      <td>digby morrell born 10 october 1979 is a former...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Alfred_J._Lewy&gt;</td>\n",
       "      <td>Alfred J. Lewy</td>\n",
       "      <td>alfred j lewy aka sandy lewy graduated from un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Harpdog_Brown&gt;</td>\n",
       "      <td>Harpdog Brown</td>\n",
       "      <td>harpdog brown is a singer and harmonica player...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Franz_Rottensteiner&gt;</td>\n",
       "      <td>Franz Rottensteiner</td>\n",
       "      <td>franz rottensteiner born in waidmannsfeld lowe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/G-Enka&gt;</td>\n",
       "      <td>G-Enka</td>\n",
       "      <td>henry krvits born 30 december 1974 in tallinn ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 URI                 name  \\\n",
       "0        <http://dbpedia.org/resource/Digby_Morrell>        Digby Morrell   \n",
       "1       <http://dbpedia.org/resource/Alfred_J._Lewy>       Alfred J. Lewy   \n",
       "2        <http://dbpedia.org/resource/Harpdog_Brown>        Harpdog Brown   \n",
       "3  <http://dbpedia.org/resource/Franz_Rottensteiner>  Franz Rottensteiner   \n",
       "4               <http://dbpedia.org/resource/G-Enka>               G-Enka   \n",
       "\n",
       "                                                text  \n",
       "0  digby morrell born 10 october 1979 is a former...  \n",
       "1  alfred j lewy aka sandy lewy graduated from un...  \n",
       "2  harpdog brown is a singer and harmonica player...  \n",
       "3  franz rottensteiner born in waidmannsfeld lowe...  \n",
       "4  henry krvits born 30 december 1974 in tallinn ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load wiki data\n",
    "people = load_wiki_data(\"data/people_wiki.csv\")\n",
    "print people.shape\n",
    "people.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ở đây, ta có thể thấy tập dữ liệu của chúng ta có 59,071 văn bản liên quan đến những người nổi tiếng, được phân ra thành ba cột thông tin (URI, name, text). Ta phân tích một vài nhân vật nổi tiếng như Obama và Taylor Swift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obama\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URI</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35817</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Barack_Obama&gt;</td>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>barack hussein obama ii brk husen bm born augu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              URI          name  \\\n",
       "35817  <http://dbpedia.org/resource/Barack_Obama>  Barack Obama   \n",
       "\n",
       "                                                    text  \n",
       "35817  barack hussein obama ii brk husen bm born augu...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore\n",
    "obama = people[people[\"name\"] == \"Barack Obama\"]\n",
    "obama_row_index = obama.index.tolist()[0]\n",
    "print \"Obama\"\n",
    "obama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taylor Swift\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URI</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54264</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Taylor_Swift&gt;</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>taylor alison swift born december 13 1989 is a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              URI          name  \\\n",
       "54264  <http://dbpedia.org/resource/Taylor_Swift>  Taylor Swift   \n",
       "\n",
       "                                                    text  \n",
       "54264  taylor alison swift born december 13 1989 is a...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taylor = people[people[\"name\"] == \"Taylor Swift\"]\n",
    "taylor_row_index = taylor.index.tolist()[0]\n",
    "print \"Taylor Swift\"\n",
    "taylor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Đo độ tương tự giữa các văn bản</h2>\n",
    "\n",
    "<h3>Term-frequency (TF)</h3>\n",
    "\n",
    "Để có thể đo độ tương tự giữa các văn bản, ta cần mô hình hóa văn bản thành một vector. Cụ thể, ta sẽ sử dụng mô hình Bags of words (word count document representation). Đặc điểm của mô hình này đó là thứ tự của các từ sẽ bị loại bỏ, giá trị của các thành phần trong vector này được tính bằng cách đếm số lượng các từ xuất hiện trong văn bản đó.\n",
    "\n",
    "Ta cài đặt các hàm sau để tính Term-frequency (TF) của các từ trong văn bản\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq(word, doc):\n",
    "    return doc.count(word)\n",
    "\n",
    "def word_count(doc):\n",
    "    return len(doc)\n",
    "\n",
    "def tf(word, doc):\n",
    "    return (freq(word, doc) / float(word_count(doc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta tiến hành quan sát TF của các bài viết cho Obama và Taylor Swift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Obama term frequence\n",
      "barack 0.000305064063453\n",
      "hussein 0.000305064063453\n",
      "obama 0.00335570469799\n",
      "ii 0.000610128126907\n",
      "brk 0.000305064063453\n",
      "husen 0.000305064063453\n",
      "bm 0.000305064063453\n",
      "born 0.000610128126907\n",
      "august 0.000305064063453\n",
      "4 0.00183038438072\n",
      "1961 0.000305064063453\n",
      "is 0.00671140939597\n",
      "...\n",
      "-- Taylor Swift term frequence\n",
      "taylor 0.000434971726838\n",
      "alison 0.000434971726838\n",
      "swift 0.00521966072205\n",
      "born 0.000434971726838\n",
      "december 0.000434971726838\n",
      "13 0.000434971726838\n",
      "1989 0.000869943453676\n",
      "is 0.00478468899522\n",
      "an 0.0113092648978\n",
      "american 0.000434971726838\n",
      "singersongwriter 0.000434971726838\n",
      "raised 0.000434971726838\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# Calculate term frequency\n",
    "n_row_view = 10\n",
    "txt_obama = obama[\"text\"].tolist()[0]\n",
    "print \"-- Obama term frequence\"\n",
    "for i, word in enumerate(txt_obama.split()):\n",
    "    print word, tf(word, txt_obama)\n",
    "    if i > n_row_view:\n",
    "        print \"...\"\n",
    "        break\n",
    "\n",
    "txt_taylor = taylor[\"text\"].tolist()[0]\n",
    "print \"-- Taylor Swift term frequence\"\n",
    "for i, word in enumerate(txt_taylor.split()):\n",
    "    print word, tf(word, txt_taylor)\n",
    "    if i > n_row_view:\n",
    "        print \"...\"\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để đo độ tương tự, ta có thể sử dụng cosine similarity giữa hai vector. Hai vector A,B càng giống nhau thì giá trị trả về càng gần 1, ngược lại sẽ càng gần 0.\n",
    "\n",
    "<h3>Term frequency – inverse document frequency (TF-IDF)</h3>\n",
    "\n",
    "Tuy nhiên, vấn đề của mô hình Bag of Words đó là các từ quan trọng (important word) trong văn bản xuất hiện rất ít (từ hiếm-rare word). Ví dụ các từ thường gặp và không quan trọng: \"the\", \"player\", \"field\", \"goal\", và các từ hiếm như: \"futbol\", \"Messi\". Mà nội dung văn bản lại cần trọng số đóng góp của các từ này càng nhiều trong thành phần vector.\n",
    "\n",
    "Vậy làm thế nào để các từ hiếm này trở nên nổi bật. Nghĩa là ta sẽ làm nổi bật các từ chỉ xuất hiện ở một vài văn bản. Tương đương với các từ xuất hiện càng nhiều ở các văn bản, ta càng giảm giá trị của các từ này.\n",
    "\n",
    "Các từ hiếm thường có đặc điểm sau:\n",
    "<ul>\n",
    "    <li>Xuất hiện nhiều trong một văn bản (common locally)</li>\n",
    "    <li>Xuất hiện ít trong ngữ liệu (rare globally)</li>\n",
    "</ul>\n",
    "Do đó, ta sẽ sử dung TF-IDF để tăng giá trị cho các từ quan trọng. Trong đó, Term frequency chính là vector phân bố các từ trong văn bản vừa phân tích ở trên. Và <strong>Inverse document frequency</strong> được tính như sau:\n",
    "\n",
    "$$log \\frac{\\#docs}{1 + \\#docs \\ using \\ words} $$\n",
    "\n",
    "Từ công thức này, ta có thể thấy số từ sử dụng trong các văn bản càng nhiều thì log dần tiến về 0 tương đương với từ này kém giá trị, ngược lại số từ sử dụng trong các văn bản càng ít thì log sẽ tiến về giá trị lớn hơn.\n",
    "\n",
    "Ta sẽ cài đặt các hàm sau để tính TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_docs_containing(word, list_of_docs):\n",
    "    count = 0\n",
    "    for document in list_of_docs:\n",
    "        if freq(word, document) > 0:\n",
    "            count += 1\n",
    "    return 1 + count\n",
    "\n",
    "def idf(word, list_of_docs):\n",
    "    return math.log(len(list_of_docs) /\n",
    "                    float(num_docs_containing(word, list_of_docs)))\n",
    "\n",
    "def tf_idf(word, doc, list_of_docs):\n",
    "    return (tf(word, doc) * idf(word, list_of_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tương tự như TF, ta có thể sử dụng TF-IDF làm feature vector để tính độ tương tự giữa hai văn bản. Ta thử xem vector tf_idf của Obama và Taylor Swift trông như thế nào"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Obama TF-IDF\n",
      "barack 0.00154430738005\n",
      "hussein 0.00180716911415\n",
      "obama 0.015585147552\n",
      "ii 0.0014209997879\n",
      "brk 0.00259352920666\n",
      "husen 0.00280498350213\n",
      "bm 0.00108025559259\n",
      "born 0.00014982643437\n",
      "august 0.000598096015939\n",
      "4 0.00053922379238\n",
      "1961 0.000980911623905\n",
      "is 2.27235801477e-07\n",
      "...\n",
      "-- Taylor Swift TF-IDF\n",
      "taylor 0.00181803655017\n",
      "alison 0.00255524471547\n",
      "swift 0.030887818288\n",
      "born 0.000106814060867\n",
      "december 0.000867523015614\n",
      "13 0.000605028554147\n",
      "1989 0.00196721434908\n",
      "is 1.62000643158e-07\n",
      "an -1.91450443921e-07\n",
      "american 0.000462208415416\n",
      "singersongwriter 0.00172756895953\n",
      "raised 0.00123838837205\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# Calculate TF-IDF\n",
    "n_row_view = 10\n",
    "print \"-- Obama TF-IDF\"\n",
    "for i, word in enumerate(txt_obama.split()):\n",
    "    print word, tf_idf(word, txt_obama, people[\"text\"])\n",
    "    if i > n_row_view:\n",
    "        print \"...\"\n",
    "        break\n",
    "\n",
    "print \"-- Taylor Swift TF-IDF\"\n",
    "for i, word in enumerate(txt_taylor.split()):\n",
    "    print word, tf_idf(word, txt_taylor, people[\"text\"])\n",
    "    if i > n_row_view:\n",
    "        print \"...\"\n",
    "        break    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Truy vấn văn bản</h2>\n",
    "\n",
    "Ta áp dụng thuật toán K Nearest neighbor để tìm K văn bản tương tự với văn bản đang đọc. Đầu tiên, ta cần xây dựng ma trận TF-IDF là biểu diễn vector của tập ngữ liệu. Ở đây, ta sử dụng hai class từ scikit-learn để cài đặt gồm CountVectorizer và TfidfTransformer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Term frequency matrix: (59071, 548429)\n",
      "-- TF-IDF matrix: (59071, 548429)\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(people[\"text\"])\n",
    "print \"-- Term frequency matrix:\", X_train_counts.shape\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "tfidf_matrix = X_train_tfidf.toarray()\n",
    "print \"-- TF-IDF matrix:\", X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hai ma trận này đều có số chiều là 59,071x548,429 tương đương với 59,071 văn bản, mỗi văn bản được biểu diễn thành vector tf_idf có 548,429 chiều (số lượng từ trong ngữ liệu).\n",
    "\n",
    "Tiếp theo, ta sẽ sử dụng KNN để tìm K văn bản tương tự với từng văn bản trong ngữ liệu thông qua ma trận vector tf_idf. Sau đó, ta sẽ thử tìm xem những nhân vật nào có liên quan đến Obama và Taylor Swift nhất.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Who is closest to Obama?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URI</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35817</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Barack_Obama&gt;</td>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>barack hussein obama ii brk husen bm born augu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24478</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Joe_Biden&gt;</td>\n",
       "      <td>Joe Biden</td>\n",
       "      <td>joseph robinette joe biden jr dosf rbnt badn b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57108</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Hillary_Rodham_Cl...</td>\n",
       "      <td>Hillary Rodham Clinton</td>\n",
       "      <td>hillary diane rodham clinton hlri dan rdm klnt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38376</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Samantha_Power&gt;</td>\n",
       "      <td>Samantha Power</td>\n",
       "      <td>samantha power born september 21 1970 is an ir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38714</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Eric_Stern_(polit...</td>\n",
       "      <td>Eric Stern (politician)</td>\n",
       "      <td>eric stern is the director of operations for t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     URI  \\\n",
       "35817         <http://dbpedia.org/resource/Barack_Obama>   \n",
       "24478            <http://dbpedia.org/resource/Joe_Biden>   \n",
       "57108  <http://dbpedia.org/resource/Hillary_Rodham_Cl...   \n",
       "38376       <http://dbpedia.org/resource/Samantha_Power>   \n",
       "38714  <http://dbpedia.org/resource/Eric_Stern_(polit...   \n",
       "\n",
       "                          name  \\\n",
       "35817             Barack Obama   \n",
       "24478                Joe Biden   \n",
       "57108   Hillary Rodham Clinton   \n",
       "38376           Samantha Power   \n",
       "38714  Eric Stern (politician)   \n",
       "\n",
       "                                                    text  \n",
       "35817  barack hussein obama ii brk husen bm born augu...  \n",
       "24478  joseph robinette joe biden jr dosf rbnt badn b...  \n",
       "57108  hillary diane rodham clinton hlri dan rdm klnt...  \n",
       "38376  samantha power born september 21 1970 is an ir...  \n",
       "38714  eric stern is the director of operations for t...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build nearest matrix\n",
    "neigh = NearestNeighbors(n_neighbors=5)\n",
    "neigh.fit(X_train_tfidf)\n",
    "\n",
    "# Looking for some nearest\n",
    "(distance, found_index) = neigh.kneighbors([tfidf_matrix[obama_row_index]])\n",
    "print \"-- Who is closest to Obama?\"\n",
    "people.iloc[found_index.tolist()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Who is closest to Taylor Swift?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URI</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54264</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Taylor_Swift&gt;</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>taylor alison swift born december 13 1989 is a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Carrie_Underwood&gt;</td>\n",
       "      <td>Carrie Underwood</td>\n",
       "      <td>carrie marie underwood born march 10 1983 is a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27793</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Adele&gt;</td>\n",
       "      <td>Adele</td>\n",
       "      <td>adele laurie blue adkins mbe born 5 may 1988 k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29297</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Kelly_Clarkson&gt;</td>\n",
       "      <td>Kelly Clarkson</td>\n",
       "      <td>kelly brianne clarkson born april 24 1982 is a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1341</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Dolly_Parton&gt;</td>\n",
       "      <td>Dolly Parton</td>\n",
       "      <td>dolly rebecca parton dhl born january 19 1946 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  URI              name  \\\n",
       "54264      <http://dbpedia.org/resource/Taylor_Swift>      Taylor Swift   \n",
       "317    <http://dbpedia.org/resource/Carrie_Underwood>  Carrie Underwood   \n",
       "27793             <http://dbpedia.org/resource/Adele>             Adele   \n",
       "29297    <http://dbpedia.org/resource/Kelly_Clarkson>    Kelly Clarkson   \n",
       "1341       <http://dbpedia.org/resource/Dolly_Parton>      Dolly Parton   \n",
       "\n",
       "                                                    text  \n",
       "54264  taylor alison swift born december 13 1989 is a...  \n",
       "317    carrie marie underwood born march 10 1983 is a...  \n",
       "27793  adele laurie blue adkins mbe born 5 may 1988 k...  \n",
       "29297  kelly brianne clarkson born april 24 1982 is a...  \n",
       "1341   dolly rebecca parton dhl born january 19 1946 ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(distance, found_index) = neigh.kneighbors([tfidf_matrix[taylor_row_index]])\n",
    "print \"-- Who is closest to Taylor Swift?\"\n",
    "people.iloc[found_index.tolist()[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kết quả trả về khá hợp lý phải không nào.\n",
    "\n",
    "<h2>Mở rộng cho Topic modeling</h2>\n",
    "\n",
    "Topic modeling giúp bạn tự động phân loại văn bản vào các chủ đề do người dùng định nghĩa trước (<strong>Categorizer</strong>) hay tự động gom nhóm các văn bản cùng chủ đề lại với nhau (<strong>Clusterizer</strong>) để đánh nhãn chủ đề sau này. Với bài toán Categorizer, bạn có thể chuyển về dạng Multiclass classification. Trong bài viết này, ta sẽ biểu diễn văn bản dưới dạng vector là TF hoặc TF-IDF. Sau đó, sử dụng feature vector này để gom nhóm văn bản bằng hai phương pháp là NMF (Non-Negative Matrix Factorization) và LDA (latent Dirichlet allocation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tf-idf features for NMF...\n",
      "done in 17.672s.\n",
      "Fitting the NMF model with tf-idf features, n_samples=2000 and n_features=1000...\n",
      "done in 12.474s.\n",
      "\n",
      "Topics in NMF model:\n",
      "Topic #0:\n",
      "book published books new novel magazine writing radio writer author poetry york editor news press times series fiction written stories\n",
      "Topic #1:\n",
      "league season played football games team club baseball coach game player career seasons playing signed major goals professional cup draft\n",
      "Topic #2:\n",
      "album band released song albums records songs music rock singer single recorded solo guitar bands label record guitarist recording release\n",
      "Topic #3:\n",
      "party minister election elected member parliament government politician candidate assembly leader seat liberal council prime political democratic general elections cabinet\n",
      "Topic #4:\n",
      "film films television series directed role actor theatre award festival best actress appeared feature drama tv director production comedy roles\n",
      "Topic #5:\n",
      "world won championships team championship tour olympics cup champion medal finished racing race olympic event european competed title win place\n",
      "Topic #6:\n",
      "art museum gallery work artist arts new york design works exhibition contemporary artists fine city modern london san collection including\n",
      "Topic #7:\n",
      "music orchestra symphony opera piano composer jazz performed festival conductor musical chamber classical concert works new studied radio competition royal\n",
      "Topic #8:\n",
      "law served united president court states state district school board chief judge general new chairman university senate executive director business\n",
      "Topic #9:\n",
      "university research professor science institute phd studies society fellow sciences department college international received technology engineering theory physics member director\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "n_samples = 2000\n",
    "n_features = 1000\n",
    "n_topics = 10\n",
    "n_top_words = 20\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()\n",
    "    \n",
    "print(\"Extracting tf-idf features for NMF...\")\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2,\n",
    "                                   max_features=n_features,\n",
    "                                   stop_words='english')\n",
    "t0 = time.time()\n",
    "tfidf = tfidf_vectorizer.fit_transform(people[\"text\"])\n",
    "print(\"done in %0.3fs.\" % (time.time() - t0))\n",
    "\n",
    "# Fit the NMF model\n",
    "print(\"Fitting the NMF model with tf-idf features, \"\n",
    "      \"n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "t0 = time.time()\n",
    "nmf = NMF(n_components=n_topics, random_state=1,\n",
    "          alpha=.1, l1_ratio=.5).fit(tfidf)\n",
    "print(\"done in %0.3fs.\" % (time.time() - t0))\n",
    "\n",
    "print(\"\\nTopics in NMF model:\")\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Từ kết quả trên, ta có thể đặt tên cho Topic #0 là truyền thông, Topic #1 là thể thao, Topic #2 là âm nhạc, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tf features for LDA...\n",
      "done in 18.232s.\n",
      "Fitting LDA models with tf features, n_samples=2000 and n_features=1000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongong/virtualenv/sparklibs/lib/python2.7/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 128.404s.\n",
      "\n",
      "Topics in LDA model:\n",
      "Topic #0:\n",
      "world won team championship born championships tour time year second national title finished champion best win medal cup record race\n",
      "Topic #1:\n",
      "league played season team football games coach career club player game born playing baseball year professional seasons signed major cup\n",
      "Topic #2:\n",
      "university research professor institute international science member national studies society director award phd received fellow school american work college department\n",
      "Topic #3:\n",
      "law president united served chief court director states general board executive business years company officer appointed international rights service chairman\n",
      "Topic #4:\n",
      "university school college state american born high states california degree attended years united church served texas new received st graduated\n",
      "Topic #5:\n",
      "music album band released song records songs born recorded jazz new rock albums singer solo performed record recording known including\n",
      "Topic #6:\n",
      "film television series award festival theatre best films role director born appeared orchestra opera music directed actor tv production including\n",
      "Topic #7:\n",
      "party member election minister elected served born state committee government council house politician district political democratic general national president new\n",
      "Topic #8:\n",
      "book published books author born history writing award press writer written editor university canadian english novel work poetry canada new\n",
      "Topic #9:\n",
      "new art york work radio news media museum city including television artist born american los arts worked design magazine known\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting tf features for LDA...\")\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2,\n",
    "                                max_features=n_features,\n",
    "                                stop_words='english')\n",
    "t0 = time.time()\n",
    "tf = tf_vectorizer.fit_transform(people[\"text\"])\n",
    "print(\"done in %0.3fs.\" % (time.time() - t0))\n",
    "\n",
    "print(\"Fitting LDA models with tf features, \"\n",
    "      \"n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "lda = LatentDirichletAllocation(n_topics=n_topics, max_iter=5,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)\n",
    "t0 = time.time()\n",
    "lda.fit(tf)\n",
    "print(\"done in %0.3fs.\" % (time.time() - t0))\n",
    "\n",
    "print(\"\\nTopics in LDA model:\")\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tương tự, ta có thể đặt tên cho Topic #1 là thể thao, Topic #2 là đại học, Topic #3 là chính trị, ...\n",
    "\n",
    "<strong>Tham khảo thêm:</strong>\n",
    "<ul>\n",
    "    <li><a href=\"https://www.elastic.co/guide/en/elasticsearch/guide/current/scoring-theory.html\" target=\"_blank\" rel=\"noopener\">ElasticSearch TF/IDF</a></li>\n",
    "    <li><a href=\"https://viblo.asia/duongpham910/posts/JQVkVZgKkyd\" target=\"_blank\" rel=\"noopener\">TF-IDF ( term frequency – inverse document frequency)</a></li>\n",
    "    <li><a href=\"http://butchiso.com/2013/10/tim-hieu-ve-mo-hinh-khong-gian-vector.html\" target=\"_blank\" rel=\"noopener\">Tìm hiểu về mô hình không gian vector</a></li>\n",
    "    <li><a href=\"http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\" target=\"_blank\" rel=\"noopener\">Working With Text Data</a></li>\n",
    "    <li><a href=\"http://aimotion.blogspot.com/2011/12/machine-learning-with-python-meeting-tf.html\" target=\"_blank\" rel=\"noopener\">Machine Learning with Python: Meeting TF-IDF for Text Mining</a></li>\n",
    "    <li><a href=\"http://scikit-learn.org/stable/auto_examples/applications/topics_extraction_with_nmf_lda.html\" target=\"_blank\" rel=\"noopener\">Topic extraction with Non-negative Matrix Factorization and Latent Dirichlet Allocation</a></li>\n",
    "</ul>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
